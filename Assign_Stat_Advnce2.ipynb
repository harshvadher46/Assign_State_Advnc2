{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5d32d7-277a-4653-94fa-871c39e994d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example.\n",
    "\n",
    "'''\n",
    "Probability Mass Function (PMF) and Probability Density Function (PDF) are two fundamental concepts in probability and statistics, but they apply to different kinds of variables:\n",
    "PMF:\n",
    "--> Used for discrete random variables, which can only take a finite or countably infinite number of distinct values.\n",
    "--> It assigns a probability to each possible value the variable can take.\n",
    "--> Imagine rolling a die. Each number (1, 2, 3, 4, 5, 6) has a specific probability (1/6 in a fair die). The PMF tells you exactly how likely each outcome is.\n",
    "\n",
    "Properties:\n",
    "Every probability is non-negative (0 or positive).\n",
    "The sum of all probabilities equals 1 (all outcomes combined must be certain).\n",
    "\n",
    "PDF:\n",
    "--> Used for continuous random variables, which can take on any value within a specific range.\n",
    "--> It describes the probability density over the entire range, not for specific values.\n",
    "--> Imagine measuring the height of people. Any height between, say, 1.5m and 2m is possible. The PDF tells you how probable different heights are within that range (e.g., more people might be around 1.7m than 1.9m).\n",
    "\n",
    "Properties:\n",
    "--> Always non-negative.\n",
    "--> The integral of the PDF over the entire range equals 1 (represents the total probability).\n",
    "\n",
    "Example:\n",
    "Discrete: Flipping a coin (Heads/Tails). PMF: P(Heads) = 1/2, P(Tails) = 1/2.\n",
    "Continuous: Measuring the length of a fish. PDF: It wouldn't assign probabilities to specific lengths, but describe how likely different \n",
    "            lengths are (e.g., more fish might be between 10cm and 15cm than 5cm and 10cm).'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cc1c2b-0405-48d6-99a3-7c97a2fc281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?\n",
    "'''    \n",
    "Cumulative Distribution Function (CDF) is a function that provides the probability\n",
    "that a random variable (X) will take on a value less than or equal to a specific value (x). \n",
    "\n",
    "Definition :\n",
    "For a random variable X, the CDF is denoted as F(x) and defined as:\n",
    "F(x) = P(X ≤ x)\n",
    "\n",
    "Interpretation:\n",
    "F(x) gives you the cumulative probability up to a certain point (x) in the distribution.\n",
    "\n",
    "Example:\n",
    "Discrete variable:\n",
    "Imagine rolling a die. The CDF would look like this:\n",
    "| x (value) | F(x) (probability X ≤ x) |\n",
    "|---|:---|\n",
    "| 1 | 1/6 |\n",
    "| 2 | 2/6 |\n",
    "| 3 | 3/6 |\n",
    "| 4 | 4/6 |\n",
    "| 5 | 5/6 |\n",
    "| 6 | 1 |\n",
    "\n",
    "Continuous variable:\n",
    "    Think of waiting times for a bus. The CDF might show the probability that you'll wait less than or equal to 5 minutes, \n",
    "    10 minutes, 15 minutes, etc.\n",
    "    \n",
    "Why Use CDF:\n",
    "(1) Calculating probabilities:\n",
    "    Easily find probabilities like P(a < X ≤ b) by subtracting F(a) from F(b).\n",
    "(2) Visualizing distributions:\n",
    "    CDF plots offer a clear picture of how probabilities accumulate across the range of values.\n",
    "(3) Applying statistical tests:\n",
    "    Many statistical tests rely on the CDF, such as goodness-of-fit tests and hypothesis testing.\n",
    "    \n",
    "> CDF is non-decreasing (it can stay the same or increase, but never decrease).\n",
    "> CDF always starts at 0 and ends at 1.\n",
    "> It can be derived from the PMF or PDF, depending on the type of variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a2b7fb-2c9d-43db-924e-861a30c2f4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q3: What are some examples of situations where the normal distribution might be used as a model?\n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution.'''\n",
    "\n",
    "'''\n",
    "The normal distribution, also known as the bell curve, \n",
    "is a versatile tool used in various situations due to its bell-shaped symmetry and well-defined properties.\n",
    "\n",
    "The normal distribution, also known as the bell curve, is a versatile tool used in various situations due to its bell-shaped symmetry and well-defined properties. Here are some examples:\n",
    "\n",
    "1. Natural Phenomena:\n",
    "\n",
    "> Heights of people: The distribution of heights in a large population often closely follows a normal distribution, with the mean representing the average height and the standard deviation reflecting the variability.\n",
    "> Test scores: Standardized tests like SATs or IQ tests tend to have scores distributed normally, with most scores clustered around the mean and fewer scores falling further away.\n",
    "> Errors in measurements: When repeatedly measuring the same quantity, small random errors occur. These errors often follow a normal distribution due to the central limit theorem.\n",
    "\n",
    "2. Engineering and Technology:\n",
    "\n",
    "> Manufacturing quality control: Dimensions of manufactured parts like screws or bearings can exhibit normal distributions, allowing for control and monitoring of production processes.\n",
    "> Signal processing: Noise in electrical signals often follows a normal distribution, and the normal distribution is used to remove this noise and extract the desired signal.\n",
    "\n",
    "3. Finance and Economics:\n",
    "\n",
    "> Stock prices: Daily or weekly returns of stocks can be modeled using a normal distribution, although real-world data might deviate due to market events.\n",
    "> Economic indicators: Economic indicators like inflation or unemployment rates sometimes follow a normal distribution, allowing for prediction and analysis of economic trends.\n",
    "\n",
    "--->  The parameters of the normal distribution, mean (μ) and standard deviation (σ), directly influence its shape:\n",
    "\n",
    "Mean (μ): This defines the center of the distribution, the most likely value to occur. Moving the mean shifts the entire curve left or right without changing its spread.\n",
    "Standard Deviation (σ): This controls the spread of the distribution. A larger standard deviation indicates wider spread, with more values farther from the mean, resulting in a flatter curve. \n",
    "Conversely,a smaller standard deviation leads to a narrower, more peaked curve with values concentrated closer to the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7caafff-ea75-45c1-b08e-bcf4999562e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution. \n",
    "'''\n",
    "Importance of Normal Distribution:\n",
    "\n",
    " > The normal distribution, also known as the Gaussian distribution, holds immense importance in \n",
    "   statistics and probability for several reasons:\n",
    "   \n",
    "1. Central Limit Theorem: This crucial theorem states that under certain conditions, when you repeatedly sample from any population (even non-normal ones) with large enough sample size, \n",
    "   the distribution of the means of those samples tends to approach a normal distribution.This allows us to apply powerful statistical methods based on the normal distribution to data from diverse sources,\n",
    "   even if their original distributions are unknown.\n",
    "\n",
    "2. Mathematical Properties: The normal distribution has well-defined mathematical properties that make it easy to use and analyze. Its probability density function (PDF) can be easily calculated,\n",
    "   and various statistical tests and confidence intervals are based on its properties.\n",
    "   \n",
    "3. Benchmark and Comparison: Even when a real-world dataset deviates from the perfect normal distribution, it can still be compared to the normal distribution as a baseline or reference point.\n",
    "   This allows for assessing the normality of data, identifying outliers, and making informed decisions based on the deviation patterns\n",
    "   \n",
    "Real-life Examples:\n",
    "1. Predicting Exam Scores:Standardized tests like SATs or IQ tests often rely on the normal distribution to interpret scores. The mean score represents the average performance, and the standard deviation indicates the spread of scores around the mean. \n",
    "   This helps in understanding individual performance relative to the overall population.\n",
    "\n",
    "2. Quality Control in Manufacturing : Manufacturers use the normal distribution to monitor the production process of parts like screws, bearings, or electronic components. By measuring key dimensions and comparing them to a pre-defined normal distribution,\n",
    "   they can identify faulty batches and ensure product quality within acceptable tolerances.\n",
    "\n",
    "3. Evaluating Investment Strategies: When analyzing the historical returns of stocks or mutual funds, the normal distribution can be used to estimate the expected return and associated risk.\n",
    "   Investors can then compare different investment options based on their risk-return profiles and make informed decisions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ebcd34-361f-46ff-b855-b93b00c2489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
    "        Distribution and Binomial Distribution?'''\n",
    "'''\n",
    "\n",
    "The Bernoulli Distribution:\n",
    "   The Bernoulli distribution describes the probabilities associated with a single trial with exactly two possible outcomes, often labeled \"success\" and \"failure\".  \n",
    "   It's named after James Bernoulli, a Swiss mathematician who studied probability theory.\n",
    "   \n",
    "Key Characteristics:\n",
    "\n",
    "Two outcomes: It only deals with events that can have one of two mutually exclusive outcomes. For example, flipping a coin (heads/tails), \n",
    "              rolling a die and checking for even/odd, or testing positive/negative in a medical test.\n",
    "Single trial: It describes the probability of success or failure in one independent event, not repeated trials.\n",
    "Parameters: Defined by a single parameter, p, representing the probability of success. The probability of failure is then 1-p.\n",
    "\n",
    "Example:\n",
    "\n",
    "Imagine flipping a fair coin. Here, \"success\" could be getting heads and \"failure\" could be getting tails. \n",
    "Since it's a fair coin, p (success) = p (heads) = 1/2, and p (failure) = p (tails) = 1/2.\n",
    "\n",
    "The binomial distribution describes the probabilities associated with the number of successes in a series of independent Bernoulli trials. \n",
    "It extends the concept of Bernoulli distribution to multiple trials with the same two possible outcomes.\n",
    "\n",
    "Key Characteristics:\n",
    "\n",
    "Multiple trials: Applies to sequences of independent trials, each following the same Bernoulli distribution (same p for success). For example, flipping a coin 5 times, performing 10 medical tests on a patient, or drawing 3 cards from a deck with replacement.\n",
    "Number of successes: It calculates the probability of getting a specific number of successes (k) within the total number of trials (n).\n",
    "\n",
    "Parameters: Requires two parameters:\n",
    " n: The total number of independent trials.\n",
    " p: The probability of success in each individual trial (same as in the Bernoulli distribution).\n",
    "\n",
    "Example:\n",
    "\n",
    "You flip a fair coin 3 times. What is the probability of getting exactly 2 heads? Here,\n",
    "n = 3 (trials) and p = 1/2 (success for each flip). The binomial distribution helps calculate this probability.\n",
    "\n",
    "Key Differences:\n",
    "1> Number Of trials \n",
    "Bernoulli Distribution : Single trial\n",
    "Binomial Distribution : Multiple independent trials\n",
    "\n",
    "2> Outcomes:\n",
    "Bernoulli Distribution : Two mutually exclusive.  \n",
    "Binomial Distribution :  Number of successes within the trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab1248f-b6a2-4e76-9cb5-f12394a57a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater\n",
    "than 60? Use the appropriate formula and show your calculations.'''\n",
    "\n",
    "'''\n",
    "we can use the standard normal cumulative distribution function (CDF) and the following steps:\n",
    "1. Standardize the value:\n",
    "\n",
    "Calculate the z-score of the value 60 using the formula:\n",
    "z = (x - μ) / σ\n",
    "z = (60 - 50) / 10\n",
    "z = 1\n",
    "\n",
    "2. Use the standard normal CDF:\n",
    "\n",
    "Look up the probability corresponding to the calculated z-score (1) in a standard normal distribution table or use a calculator/software function.\n",
    "The probability (P(X > 60)) is the area to the right of 1 under the standard normal curve. Using a standard normal table or calculator, we find this to be approximately 0.1587.\n",
    "\n",
    "Therefore, the probability of randomly selecting an observation greater than 60 from this dataset is approximately 15.87%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd8f5a5-26e0-438e-bf57-be5eda329891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7: Explain uniform Distribution with an example.\n",
    "    '''  \n",
    "Uniform distribution is a probability distribution where every possible outcome within a specific range has an equal chance of occurring.\n",
    "It's often visualized as a rectangular shape, representing the constant probability across the range.\n",
    "\n",
    "Key characteristics:\n",
    "\n",
    "Equal probability: All values within the specified range have the same probability of being observed.\n",
    "Bounded range: The distribution is defined by a minimum and maximum value, forming a continuous interval.\n",
    "Flat shape: When graphed, the probability density function (PDF) forms a rectangle, unlike the bell-shaped curve of a normal distribution.\n",
    "\n",
    "Example:\n",
    "Imagine a bus that arrives perfectly on schedule every 10 minutes between 8:00 AM and 8:30 AM. If you arrive at the bus stop randomly within that time window, \n",
    "the probability of waiting for any particular duration between 0 and 10 minutes is the same. This scenario follows a uniform distribution.\n",
    "\n",
    "Parameters:\n",
    "a: The minimum value of the range. (In the bus example, a = 0 minutes.)\n",
    "b: The maximum value of the range. (In the bus example, b = 10 minutes.)\n",
    "\n",
    "Probability density function (PDF):\n",
    "The PDF of a uniform distribution is a straight horizontal line between a and b, with a height of 1/(b-a), representing the constant probability density:\n",
    "\n",
    "f(x) = 1 / (b - a)   for a ≤ x ≤ b\n",
    "       0             otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d66b66-0ca0-4c93-bc5f-806173c5e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8: What is the z score? State the importance of the z score.\n",
    "'''\n",
    "The z-score is a standardized score that represents how many standard deviations a specific point is away from the mean of a distribution. \n",
    "It is calculated by subtracting the mean of the distribution from a specific point's value and then dividing by the standard deviation of the distribution.\n",
    "\n",
    "Here are some of the importance of z-scores:\n",
    "\n",
    "Comparing data from different distributions: Z-scores allow you to compare data points from different distributions, \n",
    "even if the distributions have different means and standard deviations. This is because z-scores represent the number of standard deviations a point is away from the mean, regardless of the actual values of the mean and standard deviation.\n",
    "\n",
    "Identifying outliers: Z-scores can be used to identify outliers in a dataset. An outlier is a data point that is significantly different from the other data points in the dataset.\n",
    "By convention, data points with z-scores greater than 2 or less than -2 are often considered outliers.\n",
    "\n",
    "Standardizing data for machine learning: Many machine learning algorithms require that the data be standardized before they can be used. \n",
    "Standardization typically involves scaling the data to have a mean of 0 and a standard deviation of 1. Z-scores can be used to achieve this standardization.\n",
    "\n",
    "In the example above, we calculated the z-scores for a sample dataset. The z-scores show how many standard deviations each data point is away from the mean. For example, the first data point has a z-score of -0.91, \n",
    "which means it is 0.91 standard deviations below the mean.The sixth data point has a z-score of 1.78, which means it is 1.78 standard deviations above the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba93ce2e-023c-445c-ae07-ab1c0835f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem.\n",
    "'''\n",
    "The Central Limit Theorem (CLT) is a fundamental concept in probability and statistics that holds immense significance in various fields.\n",
    "It describes the behavior of the sampling distribution of means under certain conditions.\n",
    "\n",
    "Key Idea:\n",
    "\n",
    "Imagine you have a population with any distribution (not necessarily normal). If you repeatedly draw large enough samples from this population and calculate the mean of each sample,\n",
    "the distribution of those sample means will tend to approach a normal distribution, regardless of the original population's shape.\n",
    "\n",
    "Conditions:\n",
    "Independent samples: Each sample must be drawn independently from the population, meaning previous draws have no influence on subsequent ones.\n",
    "Large enough sample size: While the exact threshold varies depending on the population distribution, the theorem generally applies well for sample sizes greater than 30.\n",
    "\n",
    "Significance:\n",
    "    1. Justifies the use of normal distribution: Even if real-world data doesn't perfectly follow a normal distribution, if the sample size is large enough,\n",
    "       the CLT assures that the distribution of means will be approximately normal.\n",
    "    2. Confidence intervals and hypothesis testing: Many statistical methods, \n",
    "       like confidence intervals and hypothesis testing, rely on the normality assumption.\n",
    "    3. Simplifies complex problems: Analyzing complex distributions can be challenging. The CLT allows us to approximate the behavior of sample means using the well-understood normal distribution, \n",
    "       simplifying tasks like estimating population means, testing hypotheses, and making predictions.\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba67f78-f6d2-40ef-b1b2-c47a26264d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10: State the assumptions of the Central Limit Theorem.\n",
    "'''\n",
    "1. Independent Sampling:\n",
    "Each sample must be drawn independently from the population. This means that the selection of one sample does not influence the selection of any other sample. \n",
    "Past draws should have no bearing on future ones.\n",
    "\n",
    "2. Large Enough Sample Size:\n",
    "While the exact threshold varies depending on the population distribution, the theorem generally applies well for sample sizes greater than 30. \n",
    "As the sample size increases, the distribution of sample means becomes closer to a normal distribution, regardless of the original population's shape.\n",
    "\n",
    "3. Finite Population Variance:\n",
    "The population from which you are sampling must have a finite variance. This means that the spread of values in the population is not infinite.\n",
    "Infinite variance can lead to unexpected behavior in the sampling distribution of means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9a53b9-7a6e-4f99-ae62-d24f8f0142d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042555cd-72ea-4904-b0f0-914598ee4524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
